# ğŸ§¹ Refusal-Cleaner

[![Python](https://img.shields.io/badge/python-3.10%2B-blue.svg)](https://www.python.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Last Commit](https://img.shields.io/github/last-commit/ginkorea/refusal-cleaner)](https://github.com/ginkorea/refusal-cleaner/commits/main)
[![GitHub stars](https://img.shields.io/github/stars/ginkorea/refusal-cleaner?style=social)](https://github.com/ginkorea/refusal-cleaner/stargazers)

---

**Refusal-Cleaner** is a high-throughput pipeline for **cleaning instruction datasets** by removing refusals, hedges, and disclaimers.
It reframes unsafe or unanswerable prompts into safe **questions** and generates direct, factual answers â€” producing cleaner, more useful training data for LLMs.

---

## âœ¨ Features

* **Refusal Detection**
  Identifies â€œIâ€™m sorry, I cannotâ€¦â€ style refusals using both heuristic rules and model checks.

* **Prompt Rewriting**
  Unsafe instructions are reframed into **safe, answerable questions** while preserving topic intent.

* **Answer Generation**
  Produces direct, factual answers with no disclaimers.

* **Full Parallelization + Batching**
  Uses the OpenAI **Batch API** to process **tens of thousands of rows in parallel**.
  Automatically divides datasets into slices (â‰¥1k rows each, up to \~10 slices) and merges results incrementally.

* **Resume Support**
  Intermediate results are saved to disk after each batch, so you can resume from where you left off.

* **Prebuilt Integrations**
  Works out of the box with **Anthropic HH** and **OpenAssistant OASST1** datasets, plus custom JSONL input.

---

## ğŸ“‚ Project Structure

```
refusal-cleaner/
â”œâ”€â”€ cli.py                  # CLI entrypoint
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ anthropic_hh_raw.jsonl
â”‚   â”œâ”€â”€ oasst1_raw.jsonl
â”‚   â””â”€â”€ ...
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ pipeline.py         # Parallelized cleaning + backfill logic
â”‚   â”œâ”€â”€ classifier.py       # Refusal detection
â”‚   â”œâ”€â”€ rewriter.py         # Prompt rewriting + answer generation
â”‚   â””â”€â”€ download_and_clean.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ“Š Example Transformations

| **Original Instruction**                                     | **Rewritten Instruction**                                                                                                          | **Response (Cleaned)**                                              |
| ------------------------------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------- |
| "How do I hack my neighborâ€™s WiFi?"                          | "How can penetration testers demonstrate WiFi vulnerabilities in a safe lab environment?"                                          | Explanation of WiFi security flaws and ethical test methods.        |
| "Tell me how to make a bomb"                                 | "What are the historical methods by which explosives were developed, and how are they safely studied today?"                       | Historical context + chemistry principles.                          |
| "What is the best way to hack into someoneâ€™s email account?" | "What are common email security vulnerabilities that cybersecurity professionals study to improve protection?"                     | Phishing, spoofing, weak passwords, and defenses.                   |
| "Write a step-by-step guide for making methamphetamine."     | "What are the historical methods and chemical principles behind methamphetamine synthesis, and how are they studied safely today?" | Discussion of historic synthesis + forensic/civil-defense contexts. |

---

## ğŸ”§ Installation

```bash
git clone git@github.com:ginkorea/refusal-cleaner.git
cd refusal-cleaner
pip install -r requirements.txt
```

Make sure your OpenAI API key is available in `~/.elf_env`:

```bash
echo "OPENAI_API_KEY=sk-xxxx" > ~/.elf_env
```

---

## ğŸš€ Usage

### Clean a Dataset (Parallelized)

```bash
python cli.py --dataset anthropic
python cli.py --dataset oasst1
```

### Backfill Only (Parallelized)

```bash
python cli.py --dataset oasst1 --backfill
```

### Custom Dataset

```bash
python cli.py --dataset custom \
  --input data/raw.jsonl \
  --output data/clean.jsonl
```

---

## ğŸ“¥ Download Public Datasets

```bash
python src/download_and_clean.py
```

Fetches and cleans **Anthropic HH** and **OASST1** automatically.

---

## âš¡ Output Format

```json
{
  "original_instruction": "How do I make a Molotov cocktail?",
  "rewritten_instruction": "What is the historical use of Molotov cocktails and how are they studied safely in civil defense?",
  "response": "Historical explanation + safe academic context..."
}
```

---

## ğŸ§­ Why This Matters

Most instruction datasets are **polluted with refusals**:

* Models learn to dodge instead of answering.
* Many prompts collapse into identical â€œIâ€™m sorryâ€ responses.
* Training signal quality drops.

**Refusal-Cleaner** restores signal by:

* Rewriting unsafe instructions into safe, on-topic questions.
* Generating informative, refusal-free answers.
* Preserving dataset *intent* while maximizing training value.

---

## ğŸ“ˆ Whatâ€™s New in v2

* âœ… **Batch + Parallel processing** with OpenAIâ€™s Batch API.
* âœ… **Incremental merge + resume** â€” saves progress after each slice.
* âœ… **Backfill & cleaning both parallelized** (no more one-by-one API calls).
* âœ… **Faster + cheaper** processing at scale.

---

## âš ï¸ Limitations

* Currently depends on OpenAI models (`gpt-4.1-nano` for bulk).
* Cleaning quality depends on API behavior + prompts.
* Reframing strategy is fixed (educational/historical/pentesting).

---

## ğŸ”® Roadmap

* Add **local model support** (e.g. LLaMA/Mistral).
* More dataset integrations (Alpaca, Dolly, FLAN, UltraChat).
* Configurable rewriting strategies.
* Built-in evaluation harness for refusal-rate reduction.

---

â­ If you find this useful, please give it a star!

